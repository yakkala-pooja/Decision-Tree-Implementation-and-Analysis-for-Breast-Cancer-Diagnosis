{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d76a21-d429-4e8d-a984-7a1abf150d71",
   "metadata": {},
   "source": [
    "**Importing required libraries\n",
    "Getting Train, Validation and Test datasets\n",
    "Encoding Class Label (y)\n",
    "Dividing the Datasets as X and Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ae1b82-a71d-4282-9219-6f2f821da8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import scipy.stats as stats\n",
    "\n",
    "df = pd.read_csv('wdbc_train.csv')\n",
    "dev = pd.read_csv('wdbc_dev.csv')\n",
    "\n",
    "df['Diagnosis'] = (df['Diagnosis'] == 'M').astype(int)\n",
    "dev['Diagnosis'] = (dev['Diagnosis'] == 'M').astype(int)\n",
    "names = df.columns[:-1].tolist()\n",
    "\n",
    "X = df[names].values\n",
    "Y = df['Diagnosis'].values.reshape(-1,1)\n",
    "\n",
    "devX = dev[names].values\n",
    "devY = dev['Diagnosis'].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62811725-cad8-4ccb-85dc-2ff8a10ec030",
   "metadata": {},
   "source": [
    "**Creating a Decision Tree Node class and Decision Tree class with binning data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469f9604-c879-4828-b642-083c0e090d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNode():\n",
    "\n",
    "    def __init__(self, attribute=None, threshold=None, leftsub=None, rightsub=None, gain=None, value=None):\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.rightsub = rightsub\n",
    "        self.leftsub = leftsub\n",
    "        self.gain = gain\n",
    "        self.value = value\n",
    "\n",
    "class DT():\n",
    "\n",
    "    def __init__(self, max_depth=30, mode=\"entropy\", chithres=0.05):\n",
    "        self.max_depth = max_depth\n",
    "        self.mode = mode\n",
    "        self.chithres = chithres\n",
    "\n",
    "    def splitdata(self, dataset, attribute, threshold):\n",
    "        ltemp = dataset[:, attribute] <= threshold\n",
    "        leftset = dataset[ltemp]\n",
    "        rtemp = dataset[:, attribute] > threshold\n",
    "        rightset = dataset[rtemp]\n",
    "        return leftset, rightset\n",
    "\n",
    "    def entropy(self, y):\n",
    "        entropy = 0\n",
    "        labels = np.unique(y)\n",
    "        for label in labels:\n",
    "            pl = len(y[y == label]) / len(y)\n",
    "            entropy += -pl * np.log2(pl) if pl > 0 else 0\n",
    "        return entropy\n",
    "\n",
    "    def gini(self, y):\n",
    "        gini = 1\n",
    "        labels = np.unique(y)\n",
    "        for label in labels:\n",
    "            pg = len(y[y == label]) / len(y)\n",
    "            gini -= pg ** 2\n",
    "        return gini\n",
    "\n",
    "    def infogain(self, parent, left, right):\n",
    "        wright = len(right) / len(parent)\n",
    "        wleft = len(left) / len(parent)\n",
    "        weighted_en = (wleft * self.entropy(left)) + (wright * self.entropy(right))\n",
    "        return self.entropy(parent) - weighted_en\n",
    "\n",
    "    def ginigain(self, parent, left, right):\n",
    "        wright = len(right) / len(parent)\n",
    "        wleft = len(left) / len(parent)\n",
    "        weighted_gini = (wleft * self.gini(left)) + (wright * self.gini(right))\n",
    "        return self.gini(parent) - weighted_gini\n",
    "\n",
    "    def chisquare(self, parent, left, right):\n",
    "        unclass = np.unique(parent)\n",
    "        size = len(parent)\n",
    "        obleft = [np.sum(left == cls) for cls in unclass]\n",
    "        obright = [np.sum(right == cls) for cls in unclass]\n",
    "        totcount = [np.sum(parent == cls) for cls in unclass]\n",
    "        exleft = [(count * len(left)) / size for count in totcount]\n",
    "        exright = [(count * len(right)) / size for count in totcount]\n",
    "        chisq = 0\n",
    "        for obsl, obsr, expl, expr in zip(obleft, obright, exleft, exright):\n",
    "            chisq += ((obsl - expl) ** 2 / expl) if expl > 0 else 0\n",
    "            chisq += ((obsr - expr) ** 2 / expr) if expr > 0 else 0\n",
    "        \n",
    "        return chisq\n",
    "\n",
    "    def bestsplit(self, dataset, nattributes):\n",
    "        splitresult = {'gain': -1, 'attribute': None, 'threshold': None}\n",
    "        for index in range(nattributes):\n",
    "            values = dataset[:, index]\n",
    "            thresholds = np.unique(values)\n",
    "            for threshold in thresholds:\n",
    "                leftdset, rightdset = self.splitdata(dataset, index, threshold)\n",
    "                if len(leftdset) and len(rightdset):\n",
    "                    parent = dataset[:, -1]\n",
    "                    lefty, righty = leftdset[:, -1], rightdset[:, -1]\n",
    "\n",
    "                    if self.mode == \"entropy\":\n",
    "                        gain = self.infogain(parent, lefty, righty)\n",
    "                    elif self.mode == \"gini\":\n",
    "                        gain = self.ginigain(parent, lefty, righty)\n",
    "                    chival = self.chisquare(parent, lefty, righty)\n",
    "                    pval = 1 - stats.chi2.cdf(chival, df=len(np.unique(parent)) - 1)\n",
    "                    if pval < self.chithres and gain > splitresult[\"gain\"]:\n",
    "                        splitresult[\"threshold\"] = threshold\n",
    "                        splitresult[\"attribute\"] = index\n",
    "                        splitresult[\"leftset\"] = leftdset\n",
    "                        splitresult[\"rightset\"] = rightdset\n",
    "                        splitresult[\"gain\"] = gain\n",
    "        return splitresult\n",
    "\n",
    "    def leafval(self, y):\n",
    "        return max(y, key=list(y).count)\n",
    "\n",
    "    def treeBuilding(self, dataset, currdepth=0):\n",
    "        X, Y = dataset[:, :-1], dataset[:, -1]\n",
    "        nsamples, nattributes = X.shape\n",
    "        if currdepth <= self.max_depth:\n",
    "            splitresult = self.bestsplit(dataset, nattributes)\n",
    "            if splitresult[\"gain\"] > 0:\n",
    "                leftnode = self.treeBuilding(splitresult[\"leftset\"], currdepth + 1)\n",
    "                rightnode = self.treeBuilding(splitresult[\"rightset\"], currdepth + 1)\n",
    "                return DTNode(splitresult[\"attribute\"], splitresult[\"threshold\"], leftnode, rightnode, splitresult[\"gain\"])\n",
    "        leaf = self.leafval(Y)\n",
    "        return DTNode(value=leaf)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        dataset = np.concatenate((X, Y.reshape(-1, 1)), axis=1)\n",
    "        self.root = self.treeBuilding(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self.prediction(x, self.root) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def prediction(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        attribute = x[node.attribute]\n",
    "        if attribute <= node.threshold:\n",
    "            return self.prediction(x, node.leftsub)\n",
    "        return self.prediction(x, node.rightsub)\n",
    "\n",
    "    def treeDiagram(self, node=None, dot=None):\n",
    "        if dot is None:\n",
    "            dot = graphviz.Digraph(comment='Decision Tree')\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if node.value is not None:\n",
    "            dot.node(str(id(node)), f\"Class: {node.value}\", shape='box')\n",
    "        else:\n",
    "            dot.node(str(id(node)), f\"Feature {node.attribute} <= {node.threshold}\")\n",
    "            if node.leftsub:\n",
    "                dot.edge(str(id(node)), str(id(node.leftsub)), label=\"True\")\n",
    "                self.treeDiagram(node.leftsub, dot)\n",
    "            if node.rightsub:\n",
    "                dot.edge(str(id(node)), str(id(node.rightsub)), label=\"False\")\n",
    "                self.treeDiagram(node.rightsub, dot)\n",
    "        return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891875ec-4b7e-443b-ae9c-af382a9f1e5d",
   "metadata": {},
   "source": [
    "**Random split function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e99bd77-4c1e-4bd3-8a79-421ca37d2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsplit(X, Y, randomstate=41, testsize=0.2):\n",
    "    nsamples = X.shape[0]\n",
    "    np.random.seed(randomstate)\n",
    "    shuffled = np.random.permutation(np.arange(nsamples))\n",
    "    ts = int(nsamples * testsize)\n",
    "    test = shuffled[:ts]\n",
    "    train = shuffled[ts:]\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = Y[train], Y[test]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b447dc9-821d-4731-8dde-973f1ccffb8d",
   "metadata": {},
   "source": [
    "**Accuracy and Informativeness Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164511b1-bff6-4341-b059-ae82e39bc0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrue, ypred):\n",
    "    ytrue = ytrue.flatten()\n",
    "    ypred = ypred.flatten()\n",
    "    totsample = len(ytrue)\n",
    "    correctpred = np.sum(ytrue == ypred)\n",
    "    return (correctpred / totsample) \n",
    "\n",
    "def precision(TP, FP):\n",
    "    if (TP + FP) > 0:\n",
    "        precision = TP / (TP + FP)\n",
    "    else: \n",
    "        precision = 0\n",
    "    return precision\n",
    "\n",
    "def specificity(TN, FP):\n",
    "    specificity = TN / (TN + FP)\n",
    "    return specificity\n",
    "\n",
    "def npv(TN, FN):\n",
    "    if (TN + FN) > 0:\n",
    "        npv = TN / (TN + FN)\n",
    "    else:\n",
    "        npv = 0\n",
    "    return npv\n",
    "\n",
    "def confusionMat(ytrue, ypred):\n",
    "    ypred = ypred.flatten()\n",
    "    ytrue = ytrue.flatten()\n",
    "    nclass = len(np.unique(ytrue))\n",
    "    for i in range(nclass):\n",
    "        mpred = ypred == i\n",
    "        mtrue = ytrue == i\n",
    "        TP = np.sum(mtrue & mpred)\n",
    "        TN = np.sum((mtrue != True) & (mpred != True))\n",
    "        FP = np.sum((mtrue != True) & mpred)\n",
    "        FN = np.sum(mtrue & (mpred != True))\n",
    "        s = TP / (TP + FN)\n",
    "        p = precision(TP, FP)\n",
    "        specific = specificity(TN, FP)\n",
    "        f = f1 = 2 * (p * s)/(p + s) if (p+s) > 0 else 0\n",
    "        fp = FP / (FP + TN)\n",
    "        fn = FN / (FN + TP)\n",
    "        n = npv(TN, FN)\n",
    "        confusionMat = np.array([[TP, FN], [FP, TN]])\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusionMat)\n",
    "    return s, specific, p, f, fp, fn, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca90ceaf-ead6-418d-9c68-4b52d392aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = randomsplit(X, Y, randomstate=42, testsize=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40601129-bfe9-4556-85ed-cec7ab3990d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "gini or entropy entropy\n"
     ]
    }
   ],
   "source": [
    "mode = input(\"gini or entropy\")\n",
    "model = DT(7, mode)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f0537-e202-496d-a343-3eb746d5a029",
   "metadata": {},
   "source": [
    "**Decision Tree Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d85b76-9df7-4da3-80f7-a2f81484f148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_treeBin.gv.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = model.treeDiagram(model.root)\n",
    "dot.render('decision_treeBin.gv', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afc8a2-b710-4077-9760-670d88f351f3",
   "metadata": {},
   "source": [
    "**Validation with Dev dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724bcb87-9e69-4e54-a050-e4ff20fc2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "devXtrain, devXtest, devYtrain, devYtest = randomsplit(devX, devY, randomstate=42, testsize=1)\n",
    "\n",
    "prediction = model.predict(devXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2d1341-4818-4125-a3a5-e7c18ca69dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Accuracy: 0.9649122807017544\n",
      "Model's Confusion Matrix:\n",
      "Confusion Matrix:\n",
      "[[71  0]\n",
      " [ 4 39]]\n",
      "Confusion Matrix:\n",
      "[[39  4]\n",
      " [ 0 71]]\n",
      "Recall: 0.9069767441860465\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 0.951219512195122\n",
      "FPR Score: 0.0\n",
      "FNR Score: 0.09302325581395349\n",
      "NVP Score: 0.9466666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"application/pdf\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model's Accuracy: {accuracy(devYtest, prediction)}\")\n",
    "print(f\"Model's Confusion Matrix:\")\n",
    "recall, sp, p, f1, fpr, fnr, nvp = confusionMat(devYtest, prediction)\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Specificity: {sp}\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"FPR Score: {fpr}\")\n",
    "print(f\"FNR Score: {fnr}\")\n",
    "print(f\"NVP Score: {nvp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc9d88-bfb7-4406-bbcd-e1dbd4631bc0",
   "metadata": {},
   "source": [
    "**Testing with Binning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522fdac8-eafd-4a8a-9da9-039e8490b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1l\u001b>[1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1            \u001b[22;38H\u001b[m\u001b[m                           \u001b[2;1H                                                                                \u001b[3;1H                                                                                \u001b[4;1H                                                                                \u001b[5;1H                                                                                \u001b[6;1H                                                                                \u001b[7;1H                                                                                \u001b[8;1H                                                                                \u001b[9;1H                                                                                \u001b[10;1H                                                                                \u001b[11;1H                                                                                \u001b[12;1H                                                                                \u001b[13;1H                                                                                \u001b[14;1H                                                                                \u001b[15;1H                                                                                \u001b[16;1H                                                                                \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                              \u001b[4h\u001b[37m\u001b[40m \u001b[4l\u001b[H\u001b[m\u001b[m\u001b[37m\u001b[40m\u001b[m\u001b[m\u001b[21B\u001b[33m\u001b[44m\u001b[1mGetting file://localhost/home/stu5/s18/py9363/PS1-yakkala/decision_treeBin.gv.p \u001b[22;80H\u001b[m\u001b[m\n",
      " 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
      " 1 0 0]\n",
      "Model's Accuracy: 0.956140350877193\n",
      "Model's Balanced Accuracy:\n",
      "Confusion Matrix:\n",
      "[[72  0]\n",
      " [ 5 37]]\n",
      "Confusion Matrix:\n",
      "[[37  5]\n",
      " [ 0 72]]\n",
      "Recall: 0.8809523809523809\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 0.9367088607594937\n",
      "FPR Score: 0.0\n",
      "FNR Score: 0.11904761904761904\n",
      "NVP Score: 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('wdbc_test.csv')\n",
    "test['Diagnosis'] = (test['Diagnosis'] == 'M').astype(int)\n",
    "names = test.columns[:-1].tolist()\n",
    "Xtest = test[names].values\n",
    "Ytest = test['Diagnosis'].values.reshape(-1,1)\n",
    "\n",
    "tXtrain, tXtest, tYtrain, tYtest = randomsplit(Xtest, Ytest, randomstate=42, testsize=1)\n",
    "py = model.predict(tXtest)\n",
    "print(py)\n",
    "print(f\"Model's Accuracy: {accuracy(tYtest, py)}\")\n",
    "print(f\"Model's Balanced Accuracy:\")\n",
    "recall, sp, p, f1, fpr, fnr, nvp = confusionMat(tYtest, py)\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Specificity: {sp}\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"FPR Score: {fpr}\")\n",
    "print(f\"FNR Score: {fnr}\")\n",
    "print(f\"NVP Score: {nvp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e05d2f-a52b-4e77-a6f8-0a19d5fd6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Accuracy: 0.9736842105263158\n",
      "Model's Balanced Accuracy:\n",
      "Confusion Matrix:\n",
      "[[72  0]\n",
      " [ 3 39]]\n",
      "Confusion Matrix:\n",
      "[[39  3]\n",
      " [ 0 72]]\n",
      "Recall: 0.9285714285714286\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "F1 Score: 0.962962962962963\n",
      "FPR Score: 0.0\n",
      "FNR Score: 0.07142857142857142\n",
      "NVP Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "mt = DT(5, mode='entropy')\n",
    "mt.fit(Xtrain, Ytrain)\n",
    "\n",
    "pi = mt.predict(tXtest)\n",
    "print(f\"Model's Accuracy: {accuracy(tYtest, pi)}\")\n",
    "print(f\"Model's Balanced Accuracy:\")\n",
    "recall, sp, p, f1, fpr, fnr, nvp = confusionMat(tYtest, pi)\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Specificity: {sp}\")\n",
    "print(f\"Precision: {p}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"FPR Score: {fpr}\")\n",
    "print(f\"FNR Score: {fnr}\")\n",
    "print(f\"NVP Score: {nvp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669b1ea-2dbd-40cc-b7a6-9ee4f8515108",
   "metadata": {},
   "source": [
    "**Creating our own binning Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7628d6-e75d-4b54-a75d-5e94f50ce5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Radius  Texture  Perimeter    Area  Smoothness  Compactness  Concavity  \\\n",
      "0   20.57    17.77     132.90  1326.0     0.08474      0.07864     0.0869   \n",
      "1   19.69    21.25     130.00  1203.0     0.10960      0.15990     0.1974   \n",
      "2   11.42    20.38      77.58   386.1     0.14250      0.28390     0.2414   \n",
      "3   18.25    19.98     119.60  1040.0     0.09463      0.10900     0.1127   \n",
      "4   13.00    21.82      87.50   519.8     0.12730      0.19320     0.1859   \n",
      "\n",
      "   ConcavePoints  Symmetry  FractalDimension  ...  worstRadius_bin  \\\n",
      "0        0.07017    0.1812           0.05667  ...                5   \n",
      "1        0.12790    0.2069           0.05999  ...                5   \n",
      "2        0.10520    0.2597           0.09744  ...                2   \n",
      "3        0.07400    0.1794           0.05742  ...                5   \n",
      "4        0.09353    0.2350           0.07389  ...                3   \n",
      "\n",
      "   worstTexture_bin  worstPerimeter_bin  worstArea_bin  worstSmoothness_bin  \\\n",
      "0                 2                   5              5                    2   \n",
      "1                 3                   5              5                    4   \n",
      "2                 3                   3              2                    5   \n",
      "3                 3                   5              5                    4   \n",
      "4                 4                   3              3                    5   \n",
      "\n",
      "   worstCompactness_bin  worstConcavity_bin  worstConcavePoints_bin  \\\n",
      "0                     2                   3                       4   \n",
      "1                     5                   5                       5   \n",
      "2                     5                   5                       5   \n",
      "3                     3                   4                       5   \n",
      "4                     5                   5                       5   \n",
      "\n",
      "   worstSymmetry_bin  worstFractalDimension_bin  \n",
      "0                  2                          4  \n",
      "1                  5                          4  \n",
      "2                  5                          5  \n",
      "3                  4                          3  \n",
      "4                  5                          5  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('wdbc_train_raw.csv')\n",
    "fcolumns = data.columns[:30]\n",
    "nbins = 6\n",
    "for col in fcolumns:\n",
    "    data[col + '_bin'] = pd.qcut(data[col], q=nbins, labels=False)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90349e-6658-4922-863d-23c7d335ea10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
